{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import time\n",
    "import os\n",
    "import logging\n",
    "import json\n",
    "import requests\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='App_Stream_ServerStatus.log', encoding='utf-8', level=logging.ERROR, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Crentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "CONSUMER_KEY = config['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = config['CONSUMER_SECRET']\n",
    "BEARER_TOKEN = config['BEARER_TOKEN']\n",
    "BEARER_TOKEN_2 = config['BEARER_TOKEN_2']\n",
    "BEARER_TOKEN_3 = config['BEARER_TOKEN_3']\n",
    "BEARER_TOKEN_4 = config['BEARER_TOKEN_4']\n",
    "BEARER_TOKEN_5 = config['BEARER_TOKEN_5']\n",
    "BEARER_TOKEN_6 = config['BEARER_TOKEN_6']\n",
    "BEARER_TOKEN_7 = config['BEARER_TOKEN_7']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Users IDs for Streaming API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames_sample  = pd.read_csv(\"data/unique_1500users.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {BEARER_TOKEN}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def main(url, params):\n",
    "    json_response = connect_to_endpoint(url, params)\n",
    "    # print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # user_ids = []\n",
    "# for _, row in df.iterrows():\n",
    "#     username = row[0]\n",
    "#     search_url = f\"https://api.twitter.com/2/users/by/username/{username}\"\n",
    "\n",
    "#     output_tweets = main(search_url, None)\n",
    "#     try:\n",
    "#         user_id = output_tweets['data']['id']\n",
    "#         user_ids.append(user_id)\n",
    "#     except:\n",
    "#         pass\n",
    "#     # time.sleep(1)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stream API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# StreamListener class inherits from tweepy.StreamListener and overrides on_status/on_error methods.\n",
    "class Stream(tweepy.Stream):\n",
    "    def on_status(self, status):\n",
    "        print(status.id_str)\n",
    "        # if \"retweeted_status\" attribute exists, flag this tweet as a retweet.\n",
    "        is_retweet = hasattr(status, \"retweeted_status\")\n",
    "\n",
    "        # check if text has been truncated\n",
    "        if hasattr(status,\"extended_tweet\"):\n",
    "            text = status.extended_tweet[\"full_text\"]\n",
    "        else:\n",
    "            text = status.text\n",
    "\n",
    "        # check if this is a quote tweet.\n",
    "        is_quote = hasattr(status, \"quoted_status\")\n",
    "        quoted_text = \"\"\n",
    "        if is_quote:\n",
    "            # check if quoted tweet's text has been truncated before recording it\n",
    "            if hasattr(status.quoted_status,\"extended_tweet\"):\n",
    "                quoted_text = status.quoted_status.extended_tweet[\"full_text\"]\n",
    "            else:\n",
    "                quoted_text = status.quoted_status.text\n",
    "\n",
    "        # remove characters that might cause problems with csv encoding\n",
    "        remove_characters = [\",\",\"\\n\"]\n",
    "        for c in remove_characters:\n",
    "            text.replace(c,\" \")\n",
    "            quoted_text.replace(c, \" \")\n",
    "\n",
    "        with open(\"out.csv\", \"a\", encoding='utf-8') as f:\n",
    "            f.write(\"%s,%s,%s,%s,%s,%s\\n\" % (status.created_at,status.user.screen_name,is_retweet,is_quote,text,quoted_text))\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Encountered streaming error (\", status_code, \")\")\n",
    "        sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(data=[StreamRule(value='Tweepy', tag=None, id='1622467826098540547')], includes={}, errors=[], meta={'sent': '2023-02-06T05:30:48.416Z', 'summary': {'created': 1, 'not_created': 0, 'valid': 1, 'invalid': 0}})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_client = tweepy.StreamingClient(BEARER_TOKEN)\n",
    "streaming_client.add_rules(tweepy.StreamRule(\"Tweepy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_items(list_of_dict: list, key_name: str) -> list:\n",
    "    if not list_of_dict: # If list_of_dict is None\n",
    "        return []\n",
    "    return [entity[key_name] for entity in list_of_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities(tweet_entities: dict, object_dict: dict, prefix: str = '') -> dict:\n",
    "    entities_dict = defaultdict(list)\n",
    "\n",
    "    # Retrieve Entities Objects\n",
    "    for object_name, key_name in object_dict.items():\n",
    "        column_name = f\"{prefix}{object_name}_list\"\n",
    "        # print(object_name)\n",
    "        entities_dict[column_name] = get_list_of_items(tweet_entities.get(object_name), key_name)\n",
    "    return entities_dict\n",
    "    # entities_dict['hashtags_list'] = get_list_of_items(tweet_entities['hashtags'], 'tag')\n",
    "    # entities_dict['urls_list'] = get_list_of_items(tweet_entities['urls'], 'expanded_url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dict_object(object_dict: dict, column_prefix: str,key_names_list: list = []) -> dict:\n",
    "    \"\"\"Return key,value pairs from dict. Returns selected keys in key_names_list or all if key_names_list is []\n",
    "\n",
    "    Args:\n",
    "        object_dict (dict)\n",
    "        key_names_list (list)\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    result_dict = defaultdict(list)\n",
    "    for key_name, value_name in object_dict.items():\n",
    "        column_name = f\"{column_prefix}_{key_name}\"\n",
    "        if not key_names_list:\n",
    "            result_dict[column_name] = value_name\n",
    "        elif key_name in key_names_list:\n",
    "            result_dict[column_name] = value_name\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tweets_columns = [\n",
    "    'id', 'author_id', 'possibly_sensitive', 'edit_history_tweet_ids', 'lang',\n",
    "    'source', 'reply_settings', 'text', 'created_at'\n",
    "]\n",
    "\n",
    "json_users_columns = [\n",
    "    'id', 'name', 'username', 'location', 'url', 'created_at', 'username',\n",
    "    'profile_image_url', 'profile_image_url', 'verified', 'description',\n",
    "    'protected'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_columns = [\n",
    "    'possibly_sensitive', 'text', 'source', 'id', 'created_at', 'lang', 'reply_settings', 'author_id', 'edit_history_tweet_ids', \n",
    "    'hashtags_list', 'urls_list', 'public_metrics_retweet_count', 'public_metrics_reply_count', 'public_metrics_like_count', \n",
    "    'public_metrics_quote_count', 'pagination_token', 'current_time'\n",
    "]\n",
    "\n",
    "user_columns = [\n",
    "    'profile_image_url', 'username', 'protected', 'name', 'id', 'description', \n",
    "    'created_at', 'verified', 'location', 'url_urls_list', 'description_hashtags_list', 'description_urls_list', 'description_mentions_list',\n",
    "    'description_cashtags_list', 'public_metrics_followers_count', 'public_metrics_following_count', 'public_metrics_tweet_count', \n",
    "    'public_metrics_listed_count', 'current_time'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StreamingClient(tweepy.StreamingClient):\n",
    "\n",
    "    # def on_tweet(self, tweet):\n",
    "    #     # print(status.id_str)\n",
    "    #     # # if \"retweeted_status\" attribute exists, flag this tweet as a retweet.\n",
    "    #     # is_retweet = hasattr(status, \"retweeted_status\")\n",
    "\n",
    "    #     # # check if text has been truncated\n",
    "    #     # if hasattr(status,\"extended_tweet\"):\n",
    "    #     #     text = status.extended_tweet[\"full_text\"]\n",
    "    #     # else:\n",
    "    #     #     text = status.text\n",
    "\n",
    "    #     # # check if this is a quote tweet.\n",
    "    #     # is_quote = hasattr(status, \"quoted_status\")\n",
    "    #     # quoted_text = \"\"\n",
    "    #     # if is_quote:\n",
    "    #     #     # check if quoted tweet's text has been truncated before recording it\n",
    "    #     #     if hasattr(status.quoted_status,\"extended_tweet\"):\n",
    "    #     #         quoted_text = status.quoted_status.extended_tweet[\"full_text\"]\n",
    "    #     #     else:\n",
    "    #     #         quoted_text = status.quoted_status.text\n",
    "\n",
    "    #     # # remove characters that might cause problems with csv encoding\n",
    "    #     # remove_characters = [\",\",\"\\n\"]\n",
    "    #     # for c in remove_characters:\n",
    "    #     #     text.replace(c,\" \")\n",
    "    #     #     quoted_text.replace(c, \" \")\n",
    "    #     print(tweet)\n",
    "    #     with open(\"out.csv\", \"a\", encoding='utf-8') as f:\n",
    "    #         f.write(\"%s\\n\" % (tweet.id))\n",
    "    def on_data(self ,raw_data):\n",
    "        tweets_list_for_dataframe = []\n",
    "        users_list_for_dataframe = []\n",
    "        # print(raw_data)\n",
    "        output_tweets = json.loads(raw_data)\n",
    "        # If no data found:\n",
    "        if output_tweets.get('data'):\n",
    "            logging.warning(f'No data found for userId')\n",
    "            # continue\n",
    "            # hast_next_token = False\n",
    "            # return\n",
    "            tweet = output_tweets['data']\n",
    "            # Get new columns\n",
    "            if not tweet.get('entities'):\n",
    "                entities_dict = parse_entities({}, {'hashtags': 'tag', 'urls': 'expanded_url'})\n",
    "            else:\n",
    "                entities_dict = parse_entities(tweet['entities'], {'hashtags': 'tag', 'urls': 'expanded_url'})\n",
    "\n",
    "            if not tweet.get('public_metrics'):\n",
    "                public_metrics_dict = expand_dict_object({}, 'public_metrics')\n",
    "            else:\n",
    "                public_metrics_dict = expand_dict_object(tweet['public_metrics'], 'public_metrics')\n",
    "\n",
    "            # Filter out unwanted columns\n",
    "            tweet = {key: tweet[key] for key in tweet.keys() if key in json_tweets_columns}\n",
    "\n",
    "                            # Combine dicts\n",
    "            tweet = {**tweet, **entities_dict, **public_metrics_dict, 'current_time': datetime.now()}\n",
    "            with open(f\"data/tweets-stream.csv\", \"a+\", encoding='utf-8') as f:\n",
    "                tweet_csv = [ tweet.get(col) for col in tweet_columns]\n",
    "                write = csv.writer(f)\n",
    "                write.writerows([tweet_csv])\n",
    "\n",
    "            for user in output_tweets['includes']['users']:\n",
    "                # Get new columns\n",
    "                if (not user.get('entities')) or (not user.get('entities').get('url')):\n",
    "                    url_dict = parse_entities({}, {'urls': 'expanded_url'}, prefix='url_')\n",
    "                else:\n",
    "                    url_dict = parse_entities(user['entities']['url'], {'urls': 'expanded_url'}, prefix='url_')\n",
    "\n",
    "                if (not user.get('entities')) or (not user.get('entities').get('description')):\n",
    "                    description_dict = parse_entities(\n",
    "                        {},\n",
    "                        {'hashtags': 'tag', 'urls': 'expanded_url', 'mentions': 'username', 'cashtags': 'tag'}, prefix='description_')\n",
    "                else:\n",
    "                    description_dict = parse_entities(\n",
    "                        user['entities']['description'],\n",
    "                        {'hashtags': 'tag', 'urls': 'expanded_url', 'mentions': 'username', 'cashtags': 'tag'}, prefix='description_')\n",
    "\n",
    "                user_public_metrics_dict = expand_dict_object(user['public_metrics'], 'public_metrics')\n",
    "                # Filter out unwanted columns\n",
    "                user = {key: user[key] for key in user.keys() if key in json_users_columns}\n",
    "\n",
    "                # Combine dicts\n",
    "                user = {**user, **url_dict, **description_dict, **user_public_metrics_dict, 'current_time': datetime.now()}\n",
    "                user_csv = [ user.get(col) for col in user_columns]\n",
    "                users_list_for_dataframe.append(user_csv)\n",
    "\n",
    "            if users_list_for_dataframe:\n",
    "                with open(f\"data/users-stream.csv\", \"a+\", encoding='utf-8') as f:\n",
    "                    write = csv.writer(f)\n",
    "                    write.writerows(users_list_for_dataframe)\n",
    "\n",
    "    def on_exception(self, exception):\n",
    "        logging.warning(exception)\n",
    "        print('On Exception')\n",
    "    def on_errors(self, status_code):\n",
    "        print(\"Encountered streaming error (\", status_code, \")\")\n",
    "        # sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming_client.delete_rules(['1588313169058877440', '1578971194384011265', '1578971194384011264'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query_params = {\n",
    "#     # 'query': '(from:twitterdev) has:links has:hashtags lang:en',\n",
    "#     'user_fields': ['created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld'],\n",
    "#     'tweet.fields': 'created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo',\n",
    "#     'expansions': 'author_id',\n",
    "#     'start_time': START_TIME,\n",
    "#     'end_time': END_TIME,\n",
    "#     'max_results': 500\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_filters = \"-is:retweet has:geo (from: 1283018468707770368 OR from:NWSNHC OR from:NHC_Atlantic OR from:NWSHouston OR from:NWSSanAntonio OR from:USGS_TexasRain OR from:USGS_TexasFlood OR from:JeffLindner1)\"\n",
    "user_filters = \"from: 1283018468707770368\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are using a Standard Project at the Basic access level, you can use the basic set of operators, can submit up to 25 concurrent rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames_sample_list = []\n",
    "for _, row in usernames_sample.iterrows():\n",
    "    user_filter = f'from: {row[\"screen_name\"]}'\n",
    "    usernames_sample_list.append(user_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(usernames_sample_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['from: CarlsbadDodger',\n",
       " 'from: axjus',\n",
       " 'from: PaulNewell4',\n",
       " 'from: Julio30438798',\n",
       " 'from: G_ozzy',\n",
       " 'from: FocusManAllDay1',\n",
       " 'from: debspe',\n",
       " 'from: TravelLogPak',\n",
       " 'from: hiltonholloway',\n",
       " 'from: jsette60',\n",
       " 'from: realkellerwade',\n",
       " 'from: davidgerard',\n",
       " 'from: hu_YUZHNOYE',\n",
       " 'from: tmbrown327',\n",
       " 'from: nekoyasumi_club',\n",
       " 'from: jinjinhnka',\n",
       " 'from: kamiyubiataka',\n",
       " 'from: RoyalNefertari',\n",
       " 'from: NNorma192',\n",
       " 'from: jotaefe2805',\n",
       " 'from: _udontknowmexx',\n",
       " 'from: SonyaSmith',\n",
       " 'from: JulieYAli',\n",
       " 'from: jneill',\n",
       " 'from: RobbinMilne',\n",
       " 'from: shero4hire',\n",
       " 'from: xoxa32',\n",
       " 'from: StewbieDoobyDo',\n",
       " 'from: chikausas',\n",
       " 'from: jcjax13',\n",
       " 'from: NaturalSci',\n",
       " 'from: ali_senkblei',\n",
       " 'from: marylouisemcgi7',\n",
       " 'from: sentinel2107',\n",
       " 'from: 05Chandan',\n",
       " 'from: zicbar56',\n",
       " 'from: JulesUSA6',\n",
       " 'from: AbhimanyuSilwal',\n",
       " 'from: elijahyab',\n",
       " 'from: MarkSharon_DP',\n",
       " 'from: LaReyneDEpee',\n",
       " 'from: skoushik351',\n",
       " 'from: HalpertSwanson',\n",
       " 'from: tlfmgator00',\n",
       " 'from: namidacchi25',\n",
       " 'from: CatherinePiech2',\n",
       " 'from: lenababou',\n",
       " 'from: Ma_LoJ',\n",
       " 'from: AristedesDuVal',\n",
       " 'from: VerticalLion',\n",
       " 'from: newsdrove',\n",
       " 'from: MedicoAlmayCuer',\n",
       " 'from: RobertoOshiro',\n",
       " 'from: VancliffDesign',\n",
       " 'from: Optimiste_sans',\n",
       " 'from: AllanCalvin16',\n",
       " 'from: ThingsYouNeed2K',\n",
       " 'from: RachelBrought14',\n",
       " 'from: SuzietheLip',\n",
       " 'from: SusanWoolnough',\n",
       " 'from: GinaHollin',\n",
       " 'from: DrBruceScott',\n",
       " 'from: tiller_stephen',\n",
       " 'from: rk70534',\n",
       " 'from: rlcook2219',\n",
       " 'from: chrishunt77',\n",
       " 'from: DirtRockr',\n",
       " 'from: fly_girl7',\n",
       " 'from: LMJCsTT',\n",
       " 'from: jakavanindo',\n",
       " 'from: SunshineOMS1900',\n",
       " 'from: MatriarchOMany',\n",
       " 'from: Dean90705847',\n",
       " 'from: susan_raciti',\n",
       " 'from: FeeRedfern',\n",
       " 'from: JUDEXJUDEXXX',\n",
       " 'from: PearlsStarz',\n",
       " 'from: mcgeary_michael',\n",
       " 'from: Bob_Loblaw1970',\n",
       " 'from: ArcaneKnowledge',\n",
       " 'from: Antchan8',\n",
       " 'from: itslitiantrevor',\n",
       " 'from: Convertuoso',\n",
       " 'from: sohailqsyed',\n",
       " 'from: PinkwvPink',\n",
       " 'from: szwest1',\n",
       " 'from: elise_flowers',\n",
       " 'from: 6thsensemoment',\n",
       " 'from: mm_david80920',\n",
       " 'from: mauhome7',\n",
       " 'from: sjp_ntl',\n",
       " 'from: picopicoNoRcep',\n",
       " 'from: FKraats',\n",
       " 'from: 2020Smiles',\n",
       " 'from: MyxaZZ',\n",
       " 'from: tinakeveryday1',\n",
       " 'from: esther241101',\n",
       " 'from: KeepingitTrump',\n",
       " 'from: AmacAllahRizasi',\n",
       " 'from: SneekieP',\n",
       " 'from: platospupil',\n",
       " 'from: Hennie94049187',\n",
       " 'from: npcv3110',\n",
       " 'from: scotinstowe',\n",
       " 'from: Louangie',\n",
       " 'from: stevenandre1967',\n",
       " 'from: mstfffffffff',\n",
       " 'from: GrosUsai',\n",
       " 'from: NldTmv',\n",
       " 'from: smooth19661',\n",
       " 'from: Vampire__knyte',\n",
       " 'from: marcanoserrano',\n",
       " 'from: LSW12612672511',\n",
       " 'from: AwakeNowReady',\n",
       " 'from: aseip1',\n",
       " 'from: SaveTheseDogs',\n",
       " 'from: ApprtionMission',\n",
       " 'from: Kicius_The_Cat',\n",
       " 'from: konro62168341',\n",
       " 'from: MistyFishWeave',\n",
       " 'from: AerialBolero',\n",
       " 'from: GodfreydeSain',\n",
       " 'from: Cagsil',\n",
       " 'from: henjenca',\n",
       " 'from: RobbersonJon',\n",
       " 'from: p_hannington',\n",
       " 'from: SototG',\n",
       " 'from: korimaru0206',\n",
       " 'from: lagioconda_mora',\n",
       " 'from: lstorey94_lisa',\n",
       " 'from: Linda36758099',\n",
       " 'from: britektire',\n",
       " 'from: bocajoes',\n",
       " 'from: meer_irma',\n",
       " 'from: JAHmausili',\n",
       " 'from: Jennie_Nat',\n",
       " 'from: Lilyanne381',\n",
       " 'from: finalride9277',\n",
       " 'from: yachatsnspirits',\n",
       " 'from: Christo82406026',\n",
       " 'from: heaneyp',\n",
       " 'from: Pedralve',\n",
       " 'from: 3015nyac',\n",
       " 'from: ambre_015',\n",
       " 'from: tanabe_yasu',\n",
       " 'from: FRA55',\n",
       " 'from: JacquelineWxxx',\n",
       " 'from: psarmmiey',\n",
       " 'from: maybeawriter',\n",
       " 'from: NemuSasisu',\n",
       " 'from: GlobalEcho_',\n",
       " 'from: Yankeesforever4',\n",
       " 'from: nircord',\n",
       " 'from: louisuitholland',\n",
       " 'from: ServusPecum',\n",
       " 'from: AdamRizkInc',\n",
       " 'from: RavENAgE2020',\n",
       " 'from: MZEXO',\n",
       " 'from: SciencePharmer',\n",
       " 'from: Marianellacapr1',\n",
       " 'from: Alchemist900',\n",
       " 'from: SukranKrmn',\n",
       " 'from: TOPOLANTIYISO',\n",
       " 'from: imcorvette64',\n",
       " 'from: KimberleyBfree',\n",
       " 'from: peterre76976220',\n",
       " 'from: YonSolitary',\n",
       " 'from: AriuniVA',\n",
       " 'from: novaccineforme',\n",
       " 'from: USA1Mom',\n",
       " 'from: amafera',\n",
       " 'from: ZacarHseyin',\n",
       " 'from: Lori20052008',\n",
       " 'from: peter_deighan',\n",
       " 'from: PeterTownsend2',\n",
       " 'from: DustSpri',\n",
       " 'from: basslouix',\n",
       " 'from: YeliJahRise',\n",
       " 'from: MzomuhleNtshan5',\n",
       " 'from: Sparkydoggo',\n",
       " 'from: LoveFlowercita',\n",
       " 'from: AngelaDeAngelo',\n",
       " 'from: IrelandAwake1',\n",
       " 'from: MKingscott',\n",
       " 'from: thereal_truther',\n",
       " 'from: i_M_wat_i_am',\n",
       " 'from: wible1',\n",
       " 'from: Chiroru_ne',\n",
       " 'from: tony80554056',\n",
       " 'from: CarloNewhouse',\n",
       " 'from: anahernandez230',\n",
       " 'from: SpookyJay36',\n",
       " 'from: MegaMandy1018',\n",
       " 'from: Granval04',\n",
       " 'from: mavikartal19',\n",
       " 'from: APHClarkson',\n",
       " 'from: Victoria59L',\n",
       " 'from: KarbofosnyjDyh',\n",
       " 'from: WORandthatD',\n",
       " 'from: Hlinde63',\n",
       " 'from: 55DoxMom',\n",
       " 'from: 545510',\n",
       " 'from: DigitalPatriot0',\n",
       " 'from: kreativekonnect',\n",
       " 'from: dufailly1',\n",
       " 'from: wNS5R7vUPbxFPEX',\n",
       " 'from: Dil_Aawara',\n",
       " 'from: 14nacar1414',\n",
       " 'from: ThomasVitins',\n",
       " 'from: jolynn_rice',\n",
       " 'from: avonb68',\n",
       " 'from: clyons317',\n",
       " 'from: Naceraterrienne',\n",
       " 'from: steph2monaco',\n",
       " 'from: NTwomeynoel',\n",
       " 'from: Cami68932713',\n",
       " 'from: MSpadine',\n",
       " 'from: grjenkin',\n",
       " 'from: AMITA0744',\n",
       " 'from: slah9695',\n",
       " 'from: Itukanarondanee',\n",
       " 'from: ErrolStock',\n",
       " 'from: trickyd90556041',\n",
       " 'from: SrtaAlexxa',\n",
       " 'from: fbag_mag',\n",
       " 'from: ckyys',\n",
       " 'from: crissha2016',\n",
       " 'from: Kenny180Kenny',\n",
       " 'from: dajwilson',\n",
       " 'from: LisaMar91564392',\n",
       " 'from: Dom175289678',\n",
       " 'from: DelphinePalmow1',\n",
       " 'from: 4reldill',\n",
       " 'from: PatPenn2',\n",
       " 'from: abdulmateen1979',\n",
       " 'from: HomeDabrave',\n",
       " 'from: gaizdajoon1',\n",
       " 'from: jmaxxd1',\n",
       " 'from: asphak_786',\n",
       " 'from: rain_send',\n",
       " 'from: DrFerdowsi',\n",
       " 'from: ArtAHammer',\n",
       " 'from: DrKassandraPari',\n",
       " 'from: Bobby6740',\n",
       " 'from: ana_pinson',\n",
       " 'from: REWalker6',\n",
       " 'from: bondyreva66',\n",
       " 'from: mybiznpolitics',\n",
       " 'from: TruthExposer010',\n",
       " 'from: skwisch',\n",
       " 'from: leonlaje',\n",
       " 'from: HIGHMENNATTER',\n",
       " 'from: franzyroy',\n",
       " 'from: TorquetJ',\n",
       " 'from: Scottishnotbrit',\n",
       " 'from: alfagamabetizad',\n",
       " 'from: Verovelasco',\n",
       " 'from: gorvener03',\n",
       " 'from: nwrmbing',\n",
       " 'from: polit2k',\n",
       " 'from: sorosokebot',\n",
       " 'from: fotobus',\n",
       " 'from: searcher9090',\n",
       " 'from: thetruth9999999',\n",
       " 'from: greatagain70',\n",
       " 'from: Nora0316',\n",
       " 'from: mjansen22598292',\n",
       " 'from: Aliveritas1',\n",
       " 'from: outspokenolivia',\n",
       " 'from: JeffKepele',\n",
       " 'from: sitycent',\n",
       " 'from: chasna50',\n",
       " 'from: EmperorBlargus',\n",
       " 'from: robert_suchy',\n",
       " 'from: languillem',\n",
       " 'from: chicchan',\n",
       " 'from: Sir_lifestyle',\n",
       " 'from: annafbeswick',\n",
       " 'from: Jennife11439803',\n",
       " 'from: littlorangefish',\n",
       " 'from: vicgil53',\n",
       " 'from: Cloudnician',\n",
       " 'from: minnesota_jen',\n",
       " 'from: lip4nit',\n",
       " 'from: yamladewana',\n",
       " 'from: _RestoreProject',\n",
       " 'from: Christi75367510',\n",
       " 'from: Kassandra_1909',\n",
       " 'from: Johnny_Brexit',\n",
       " 'from: IFilonczuk',\n",
       " 'from: WeeFatShug',\n",
       " 'from: MamolkcsMamol',\n",
       " 'from: TYKZaDVxZWTxaOt',\n",
       " 'from: TRHargrave',\n",
       " 'from: VivianM61425009',\n",
       " 'from: WadeScroggi',\n",
       " 'from: ChiliMosquito',\n",
       " 'from: CarronMrs',\n",
       " 'from: nais1998',\n",
       " 'from: enddebtslavery1',\n",
       " 'from: TheLastAtom',\n",
       " 'from: Ark_of_Info_2',\n",
       " 'from: MelodyMac51',\n",
       " 'from: CJJohns59301573',\n",
       " 'from: nomoreslaves',\n",
       " 'from: jrbkjrbk',\n",
       " 'from: pjwoodside',\n",
       " 'from: Gabriela_gajo',\n",
       " 'from: Krekelstein',\n",
       " 'from: StopPlaasmoorde',\n",
       " 'from: cejoaquina',\n",
       " 'from: Revoltin_Morgan',\n",
       " 'from: Roger_Smith_911',\n",
       " 'from: _Jolkaigolka',\n",
       " 'from: GuineeTags',\n",
       " 'from: Grap_1',\n",
       " 'from: Enopoletus',\n",
       " 'from: JeanetteSchmitt',\n",
       " 'from: BHanlay',\n",
       " 'from: Dusty186',\n",
       " 'from: EasyTraceGroup',\n",
       " 'from: Rehman1198',\n",
       " 'from: ChrisLancashir3',\n",
       " 'from: GrassrootsDNC',\n",
       " 'from: stunnatiff',\n",
       " 'from: christsport',\n",
       " 'from: tevet',\n",
       " 'from: 9soro',\n",
       " 'from: Fleetblue',\n",
       " 'from: thedoveness',\n",
       " 'from: justine01848685',\n",
       " 'from: kausikdatta22',\n",
       " 'from: Loulan_777',\n",
       " 'from: segajennesiss',\n",
       " 'from: VI_XII',\n",
       " 'from: alice_v1109',\n",
       " 'from: js100js100',\n",
       " 'from: Julija9Julija',\n",
       " 'from: julie07217',\n",
       " 'from: SBJDFW',\n",
       " 'from: Moosefucker',\n",
       " 'from: Henry02486291',\n",
       " 'from: SurkovAndrey',\n",
       " 'from: NorthOfAtlanta1',\n",
       " 'from: macca1969uk',\n",
       " 'from: ReenyNY',\n",
       " 'from: BoboJarvis',\n",
       " 'from: PakistanIsNoor',\n",
       " 'from: KarenKanadian',\n",
       " 'from: SALTGERL',\n",
       " 'from: Angels1stWings',\n",
       " 'from: Ringham7',\n",
       " 'from: generativist',\n",
       " 'from: PerthshireMags',\n",
       " 'from: poa_karlsson',\n",
       " 'from: Jasperlope',\n",
       " 'from: DonJuan5800',\n",
       " 'from: LilostartupLilo',\n",
       " 'from: saraart4',\n",
       " 'from: NevesJuvenil',\n",
       " 'from: zootymanda',\n",
       " 'from: NGameos',\n",
       " 'from: nisflores',\n",
       " 'from: ClwtrBkAtty',\n",
       " 'from: 74oldgal',\n",
       " 'from: DAYLEE',\n",
       " 'from: nlygo',\n",
       " 'from: MEHMETYARICI1',\n",
       " 'from: MakaNelli305',\n",
       " 'from: toddfoxauthor',\n",
       " 'from: TujyeKunywa',\n",
       " 'from: belgestousegaux',\n",
       " 'from: elenice_mano',\n",
       " 'from: apoxalyps1',\n",
       " 'from: migarubia',\n",
       " 'from: SweetCookiesme',\n",
       " 'from: KPDAD72',\n",
       " 'from: PlepsART',\n",
       " 'from: eshiet81',\n",
       " 'from: nooil4pacifists',\n",
       " 'from: PTzepKHdksuJ59G',\n",
       " 'from: techgolf44',\n",
       " 'from: collectiveUV',\n",
       " 'from: leighgt',\n",
       " 'from: NurOzkan35',\n",
       " 'from: SpectralRoar',\n",
       " 'from: sforklr',\n",
       " 'from: KingdomKobe',\n",
       " 'from: SmithTarquin',\n",
       " 'from: AnthonyLarme',\n",
       " 'from: Danuta65Danuta',\n",
       " 'from: PuaMeliaClinic',\n",
       " 'from: IMchaffie',\n",
       " 'from: susanlee52',\n",
       " 'from: SyairRevolusi',\n",
       " 'from: Justis4u2',\n",
       " 'from: SelaStarr',\n",
       " 'from: Rotterdam_anon',\n",
       " 'from: Kings_seek_her',\n",
       " 'from: martinubedizzy',\n",
       " 'from: squawkying',\n",
       " 'from: WarOnHumanity20',\n",
       " 'from: jimmcmahon3',\n",
       " 'from: gardgoldsmith',\n",
       " 'from: Gnomes4Trump',\n",
       " 'from: Lowcountry6SC',\n",
       " 'from: NYROYALKING',\n",
       " 'from: Boiarski',\n",
       " 'from: cemgildogan',\n",
       " 'from: 202clau2',\n",
       " 'from: piyococcochan2',\n",
       " 'from: Lexicon97457966',\n",
       " 'from: Beheeve',\n",
       " 'from: manngakaki',\n",
       " 'from: heraldscotland',\n",
       " 'from: Deeteckz',\n",
       " 'from: ZZsheyn',\n",
       " 'from: spagetyuse',\n",
       " 'from: PaulbernalUK',\n",
       " 'from: cristian100',\n",
       " 'from: Telegraph',\n",
       " 'from: etedalessa',\n",
       " 'from: jfrankcarr',\n",
       " 'from: OliverC85515150',\n",
       " 'from: SynphZ',\n",
       " 'from: KELLYCLELLAND1',\n",
       " 'from: Lyno45',\n",
       " 'from: NRafter',\n",
       " 'from: AhyattocameNamo',\n",
       " 'from: slimefin',\n",
       " 'from: Anarchohoodism',\n",
       " 'from: ABCBTom',\n",
       " 'from: MommyUnit',\n",
       " 'from: AeHcat',\n",
       " 'from: June19894168',\n",
       " 'from: BarbaraGoggin4',\n",
       " 'from: BobRebelles',\n",
       " 'from: BamaReb56',\n",
       " 'from: Cletus1942',\n",
       " 'from: ALBAMENDOZAPAR1',\n",
       " 'from: anico_derek',\n",
       " 'from: danichel60',\n",
       " 'from: MichaelBuerger8',\n",
       " 'from: Loreign83',\n",
       " 'from: Demo2020cracy',\n",
       " 'from: lothar214782',\n",
       " 'from: kuwait_tt1100',\n",
       " 'from: Gentlements',\n",
       " 'from: KevRolfe',\n",
       " 'from: Caron09816650',\n",
       " 'from: rutheputh',\n",
       " 'from: LitvakSteve',\n",
       " 'from: judy727z',\n",
       " 'from: BmsMatrix',\n",
       " 'from: EntelechyInc',\n",
       " 'from: BullsBlockchain',\n",
       " 'from: CTValleyPatriot',\n",
       " 'from: jeblake7',\n",
       " 'from: GGretchenmobley',\n",
       " 'from: PhilDeCarolis',\n",
       " 'from: Sofietvarno',\n",
       " 'from: cannoneerfour',\n",
       " 'from: _Grand_Wazoo_',\n",
       " 'from: LewtonSerena5',\n",
       " 'from: HumphreyPT',\n",
       " 'from: lynette67746779',\n",
       " 'from: arizonageri',\n",
       " 'from: Francolinie',\n",
       " 'from: TakmeelPAkistan',\n",
       " 'from: LoriIllia',\n",
       " 'from: NigeriaState',\n",
       " 'from: marionste',\n",
       " 'from: mhanifus',\n",
       " 'from: darthburty',\n",
       " 'from: robert0461',\n",
       " 'from: johnbramundo',\n",
       " 'from: AmericanWow2017',\n",
       " 'from: FreeUs551',\n",
       " 'from: DuncanHenry78',\n",
       " 'from: ssr57',\n",
       " 'from: LloydCosby',\n",
       " 'from: anbealach',\n",
       " 'from: kadturay',\n",
       " 'from: timbofive',\n",
       " 'from: sales_amaral',\n",
       " 'from: maggi6164',\n",
       " 'from: Imran25645287',\n",
       " 'from: perimsi_sahika',\n",
       " 'from: YarlYOMSBORG',\n",
       " 'from: shiroi_suna_',\n",
       " 'from: MrIndianAtheist',\n",
       " 'from: mrtom101',\n",
       " 'from: torpartjejen1',\n",
       " 'from: Larisa74744859',\n",
       " 'from: Sandrivaliente',\n",
       " 'from: 13tucha',\n",
       " 'from: dexerylette',\n",
       " 'from: PrrpleGrl',\n",
       " 'from: opalessense',\n",
       " 'from: Tweeta1970',\n",
       " 'from: Adriana1o5',\n",
       " 'from: stevedemaio',\n",
       " 'from: scientist_pop',\n",
       " 'from: B0tSci',\n",
       " 'from: BotForEquality',\n",
       " 'from: marilynpeake',\n",
       " 'from: ProSyn',\n",
       " 'from: JackKaj3',\n",
       " 'from: randomcaroline',\n",
       " 'from: seanmmcbride',\n",
       " 'from: marcody8',\n",
       " 'from: DIGITALDECODED1',\n",
       " 'from: rozanik56',\n",
       " 'from: COVID19TestsNow',\n",
       " 'from: alefolgarait',\n",
       " 'from: ScotlandYardCSI',\n",
       " 'from: RonInCMH',\n",
       " 'from: schraderwest',\n",
       " 'from: CarlosDPonciano',\n",
       " 'from: scrimmins53',\n",
       " 'from: snitstwits',\n",
       " 'from: Brizzy10193246',\n",
       " 'from: ResolveTSL',\n",
       " 'from: dhavidearuliah',\n",
       " 'from: rift147',\n",
       " 'from: dfreedman7',\n",
       " 'from: Camns1',\n",
       " 'from: WeaselsOf',\n",
       " 'from: AlanJCard',\n",
       " 'from: LcsNusbaum',\n",
       " 'from: IDstewardship',\n",
       " 'from: Justice30',\n",
       " 'from: ChristoPhraser',\n",
       " 'from: chandra_gego',\n",
       " 'from: shelleyjlenz',\n",
       " 'from: JuanitaIguana1',\n",
       " 'from: ML_Tweet_Bot',\n",
       " 'from: prutter_pat',\n",
       " 'from: StevenBenso',\n",
       " 'from: VilhenaSant',\n",
       " 'from: Shashwat014',\n",
       " 'from: OBrien_Kat',\n",
       " 'from: DanielA12021444',\n",
       " 'from: bearzig',\n",
       " 'from: RandomSusla',\n",
       " 'from: ScottGottliebMD',\n",
       " 'from: LauraFlowersE',\n",
       " 'from: PetersonDouglas',\n",
       " 'from: unddubistschuld',\n",
       " 'from: FShnerb',\n",
       " 'from: AndrewCFrancis',\n",
       " 'from: bridgetwolves',\n",
       " 'from: impd48',\n",
       " 'from: georgialove0916',\n",
       " 'from: avhrskmp',\n",
       " 'from: joyclee',\n",
       " 'from: DLHDara',\n",
       " 'from: routeofthesun',\n",
       " 'from: Gailhansendvm',\n",
       " 'from: matkinson956',\n",
       " 'from: RobAdamsFL',\n",
       " 'from: _Z__',\n",
       " 'from: MEISU98037829',\n",
       " 'from: david_colquhoun',\n",
       " 'from: DoubleEagle49',\n",
       " 'from: LouisBrignet',\n",
       " 'from: SuetLee4',\n",
       " 'from: nwseal11',\n",
       " 'from: krissymom2',\n",
       " 'from: KaySch53',\n",
       " 'from: DavidPenington2',\n",
       " 'from: bluedillygal',\n",
       " 'from: susieclapton',\n",
       " 'from: brianhill_53703',\n",
       " 'from: JoanJett0202',\n",
       " 'from: cardiobrief',\n",
       " 'from: LovingVolTrav',\n",
       " 'from: tryinghard1234',\n",
       " 'from: FishyOne5',\n",
       " 'from: crosscutanne',\n",
       " 'from: krutesoup',\n",
       " 'from: segmentis',\n",
       " 'from: amouretbisous',\n",
       " 'from: Pedra999',\n",
       " 'from: imthemadridista',\n",
       " 'from: AndreDolder',\n",
       " 'from: kellyfirehorse',\n",
       " 'from: mediapolitic',\n",
       " 'from: TelehealthBot',\n",
       " 'from: Miyagi37',\n",
       " 'from: acgt01',\n",
       " 'from: TiGGyZTweetZ',\n",
       " 'from: EricKratz2',\n",
       " 'from: samiamsamh',\n",
       " 'from: tracyreynolds_g',\n",
       " 'from: Asassybella',\n",
       " 'from: thejoedoe1',\n",
       " 'from: Harkaway',\n",
       " 'from: divaRuthIe',\n",
       " 'from: PATHtweets',\n",
       " 'from: platzker',\n",
       " 'from: scottevanjenk',\n",
       " 'from: TheKeeper2016',\n",
       " 'from: Jeremy13605986',\n",
       " 'from: IrishScripter',\n",
       " 'from: jerrymichalski',\n",
       " 'from: ghia1212',\n",
       " 'from: shrill_falsetto',\n",
       " 'from: tizzywoman',\n",
       " 'from: MarysLe1',\n",
       " 'from: BeverlyPilot',\n",
       " 'from: derrelldurrett',\n",
       " 'from: DervishWaking',\n",
       " 'from: ThurlowRoad',\n",
       " 'from: lb_bklyn',\n",
       " 'from: plathelibrarian',\n",
       " 'from: sunbleachedsky',\n",
       " 'from: Bubbiespics',\n",
       " 'from: AliAlsayer',\n",
       " 'from: docfreeride',\n",
       " 'from: MamaShoooo',\n",
       " 'from: Joeyus',\n",
       " 'from: mk_vs04',\n",
       " 'from: patti_foss',\n",
       " 'from: Ihavenousefora1',\n",
       " 'from: mtanichthys',\n",
       " 'from: HilarieAshton',\n",
       " 'from: AvaYodaDinosaur',\n",
       " 'from: PsychosisFuzz',\n",
       " 'from: ArTallks',\n",
       " 'from: ayee_jane',\n",
       " 'from: usagiko',\n",
       " 'from: lynn180_lynn',\n",
       " 'from: 990000',\n",
       " 'from: freelancer1a2b',\n",
       " 'from: cayost1',\n",
       " 'from: AJDMaru',\n",
       " 'from: toknell',\n",
       " 'from: Seanchai313',\n",
       " 'from: fubardaddy',\n",
       " 'from: Penny_G',\n",
       " 'from: BernieUpstateNY',\n",
       " 'from: jbryan522',\n",
       " 'from: darrenabrown',\n",
       " 'from: capalutwit',\n",
       " 'from: luciaruggiero',\n",
       " 'from: IvanZupic',\n",
       " 'from: BasiaSosnowska',\n",
       " 'from: CovidAnalyst',\n",
       " 'from: CayoCornelio',\n",
       " 'from: rizkipradipta',\n",
       " 'from: TJA4Michigan',\n",
       " 'from: takingaction4us',\n",
       " 'from: AndRChelsea',\n",
       " 'from: CopyOfOne',\n",
       " 'from: sarahc_clayton',\n",
       " 'from: volxfahradler',\n",
       " 'from: HafaRamon',\n",
       " 'from: brendaoncats',\n",
       " 'from: 17ShortFuse',\n",
       " 'from: adilbhatti_',\n",
       " 'from: DrCSWilliam',\n",
       " 'from: Delilah399',\n",
       " 'from: KwekuOA',\n",
       " 'from: gesb2',\n",
       " 'from: centristsFTW',\n",
       " 'from: KimBru49',\n",
       " 'from: StockMarcoCosta',\n",
       " 'from: sydneypadua',\n",
       " 'from: hoy2_hoy',\n",
       " 'from: IMoanalotHutchy',\n",
       " 'from: edrybicki',\n",
       " 'from: a_peterman',\n",
       " 'from: lesliebrody',\n",
       " 'from: Lindata44412835',\n",
       " 'from: MeloniaSherban',\n",
       " 'from: KCYatsko',\n",
       " 'from: Grownmangrumble',\n",
       " 'from: earthling2000s',\n",
       " 'from: hopefulcritic',\n",
       " 'from: wsu_danielle',\n",
       " 'from: Rob_Bee_Gee',\n",
       " 'from: woan',\n",
       " 'from: Jamesmarroquin',\n",
       " 'from: MickBrooks666',\n",
       " 'from: ProfEmilyOster',\n",
       " 'from: MayoClinicKids',\n",
       " 'from: Imagirlee',\n",
       " 'from: annie_hulala',\n",
       " 'from: fred_mg',\n",
       " 'from: AthaleLab',\n",
       " 'from: CDavisAllenIII',\n",
       " 'from: antoniodiasri',\n",
       " 'from: john196201',\n",
       " 'from: newtownlos',\n",
       " 'from: Kristy91808800',\n",
       " 'from: keepark',\n",
       " 'from: olfashdeb',\n",
       " 'from: joframsa',\n",
       " 'from: GPollowitz',\n",
       " 'from: LuisPabloAngel',\n",
       " 'from: Schuckscience',\n",
       " 'from: RayFinkle9911',\n",
       " 'from: natashaloder',\n",
       " 'from: donna_lenarz',\n",
       " 'from: DanMunro',\n",
       " 'from: spencersbrook',\n",
       " 'from: FoucPerotin',\n",
       " 'from: BBWriterCRD',\n",
       " 'from: bukambu_france',\n",
       " 'from: MyTwinMN',\n",
       " 'from: fpallegra',\n",
       " 'from: FreddyRoo2',\n",
       " 'from: myfriendLiz',\n",
       " 'from: sallyray5',\n",
       " 'from: AnisabelBento',\n",
       " 'from: WilsonO36040576',\n",
       " 'from: crowfreak',\n",
       " 'from: Thalassatx',\n",
       " 'from: DrSueGross',\n",
       " 'from: daveunger3',\n",
       " 'from: michaelghead',\n",
       " 'from: shellneal2501',\n",
       " 'from: randsco',\n",
       " 'from: robgo84',\n",
       " 'from: taalluq',\n",
       " 'from: ASP_MirandaS',\n",
       " 'from: RealJewNews',\n",
       " 'from: killeen_gerry',\n",
       " 'from: hentairules',\n",
       " 'from: Elischico',\n",
       " 'from: SciTechAfrica',\n",
       " 'from: pecanyasmin',\n",
       " 'from: InfamousResists',\n",
       " 'from: mirdeb',\n",
       " 'from: GrammiePammie14',\n",
       " 'from: ottawatts',\n",
       " 'from: helena_gd',\n",
       " 'from: CBLevinePhD',\n",
       " 'from: fredwalton216',\n",
       " 'from: dgermain21',\n",
       " 'from: AnitaMEndeman',\n",
       " 'from: Marco_Piani',\n",
       " 'from: MarcusPun',\n",
       " 'from: JimmyRiveraNYC',\n",
       " 'from: finneyeric',\n",
       " 'from: AnnSmit45836518',\n",
       " 'from: rdwrt',\n",
       " 'from: 4589roger',\n",
       " 'from: ciro',\n",
       " 'from: luizacaires3',\n",
       " 'from: SciencePartisan',\n",
       " 'from: melb4886',\n",
       " 'from: raven66612',\n",
       " 'from: NancyKellyMart1',\n",
       " 'from: tweetjoshtweet',\n",
       " 'from: BellaDawn01527',\n",
       " 'from: tortiegertie',\n",
       " 'from: Sonja6272',\n",
       " 'from: Giselabord',\n",
       " 'from: julimsw_juli',\n",
       " 'from: Nori_NYC',\n",
       " 'from: GHS',\n",
       " 'from: off2wine',\n",
       " 'from: ImpeachBDevos',\n",
       " 'from: ProfSomashekhar',\n",
       " 'from: paravani_g',\n",
       " 'from: NiggaTheory',\n",
       " 'from: sotnasoinotna',\n",
       " 'from: lizbon',\n",
       " 'from: fitz_arc',\n",
       " 'from: MKSafdar',\n",
       " 'from: DeenaGarzik',\n",
       " 'from: Golden_Seagul',\n",
       " 'from: itswensss',\n",
       " 'from: Ja1537Eddie',\n",
       " 'from: Lesliecnelson',\n",
       " 'from: segol60',\n",
       " 'from: TinaKendrick01',\n",
       " 'from: RyanErlewine',\n",
       " 'from: badpiratemonkey',\n",
       " 'from: operasingerBB',\n",
       " 'from: DSTCPRIISc',\n",
       " 'from: Cormac_Sheridan',\n",
       " 'from: israelinsider',\n",
       " 'from: ScienceisGlobal',\n",
       " 'from: FinkyBee',\n",
       " 'from: gooochin',\n",
       " 'from: louisa_faux',\n",
       " 'from: ZacharyBrennan',\n",
       " 'from: DNDi',\n",
       " 'from: agargmd',\n",
       " 'from: OddballPaladin',\n",
       " 'from: Lucy_wo_Diamond',\n",
       " 'from: shahana_smith',\n",
       " 'from: HabBradley',\n",
       " 'from: BT_Cozer',\n",
       " 'from: DrLindaDykes',\n",
       " 'from: parknfly07',\n",
       " 'from: zephyr9673',\n",
       " 'from: islandlife2014',\n",
       " 'from: andytoronto',\n",
       " 'from: RiskAlert',\n",
       " 'from: BurnsieAnn',\n",
       " 'from: ErikJonker',\n",
       " 'from: MacleodJust',\n",
       " 'from: drtwillett',\n",
       " 'from: NatashaPolitics',\n",
       " 'from: sportsuzie1974',\n",
       " 'from: mackaracka',\n",
       " 'from: eguellp',\n",
       " 'from: readycat',\n",
       " 'from: AgnesAyton',\n",
       " 'from: mbzhad',\n",
       " 'from: robert_veres',\n",
       " 'from: Busza_',\n",
       " 'from: catherinebuca',\n",
       " 'from: davimedinTwits',\n",
       " 'from: drdanchoi',\n",
       " 'from: ThomasAtcheson',\n",
       " 'from: Adriahanitta',\n",
       " 'from: eita_kakehashi',\n",
       " 'from: DaveOnFidalgo',\n",
       " 'from: Fr4nc3',\n",
       " 'from: spike_sr71',\n",
       " 'from: Seggitorial',\n",
       " 'from: Qweere',\n",
       " 'from: 9six7',\n",
       " 'from: sheila89062698',\n",
       " 'from: Tooda',\n",
       " 'from: JonathanDune',\n",
       " 'from: ndgree',\n",
       " 'from: xf_grely',\n",
       " 'from: rajvarshney',\n",
       " 'from: MichealYi8',\n",
       " 'from: eperakslis',\n",
       " 'from: DrAdaora',\n",
       " 'from: MarenHofstad',\n",
       " 'from: Anakanale',\n",
       " 'from: MarcelHarmon1',\n",
       " 'from: MFenderesky',\n",
       " 'from: SAIRABT',\n",
       " 'from: greenwichwriter',\n",
       " 'from: longgonesam',\n",
       " 'from: BitaScicomm',\n",
       " 'from: EvelynS51868235',\n",
       " 'from: ChannelingLlama',\n",
       " 'from: PILOTforPULM',\n",
       " 'from: DuseLu',\n",
       " 'from: HOUmanitarian',\n",
       " 'from: stephen_abbott',\n",
       " 'from: Srk1951mn',\n",
       " 'from: boehninglab',\n",
       " 'from: drpaolandmd',\n",
       " 'from: SueM21731182',\n",
       " 'from: anshulkundaje',\n",
       " 'from: wallisweaver',\n",
       " 'from: macroliter',\n",
       " 'from: trentyarwood',\n",
       " 'from: TracyLou3',\n",
       " 'from: JuliaChidley',\n",
       " 'from: akirenaleri',\n",
       " 'from: Urbanartist2',\n",
       " 'from: jlane_boston',\n",
       " 'from: FatalPolitics',\n",
       " 'from: tesla4the',\n",
       " 'from: Skittles_Is6',\n",
       " 'from: ProgGrrl',\n",
       " 'from: gavi',\n",
       " 'from: 6f6e5ba6bdc34ae',\n",
       " 'from: seawiz2',\n",
       " 'from: maudlynei',\n",
       " 'from: karla_handley',\n",
       " 'from: thsaey',\n",
       " 'from: jcmpPernu',\n",
       " 'from: joaolukasc',\n",
       " 'from: TheFallingStar',\n",
       " 'from: Kellblog',\n",
       " 'from: GarciaMorenoCla',\n",
       " 'from: infoambiental',\n",
       " 'from: art_iculate',\n",
       " 'from: pjie2',\n",
       " 'from: kelene_k',\n",
       " 'from: keetmom5',\n",
       " 'from: sageness77',\n",
       " 'from: ScottLeMagicien',\n",
       " 'from: annie04522986',\n",
       " 'from: takemusu',\n",
       " 'from: JoyAgnost',\n",
       " 'from: randybrucemoney',\n",
       " 'from: JimRosenz',\n",
       " 'from: pittbaster',\n",
       " 'from: NollyMowels',\n",
       " 'from: mbohl07',\n",
       " 'from: bethlevin',\n",
       " 'from: Peliteiro',\n",
       " 'from: Dave01053058',\n",
       " 'from: LeayLuke',\n",
       " 'from: sagetwitting',\n",
       " 'from: huskerlive',\n",
       " 'from: MichelleZenner',\n",
       " 'from: fengmanlou11',\n",
       " 'from: DeeJargon',\n",
       " 'from: Rosagath',\n",
       " 'from: 027queen',\n",
       " 'from: MaxFromQuebec',\n",
       " 'from: calmarten',\n",
       " 'from: phunphunphun',\n",
       " 'from: seriousdoctor',\n",
       " 'from: GanjasmokerCb',\n",
       " 'from: jane__eden',\n",
       " 'from: davidpaulspeak',\n",
       " 'from: 4DAConsultancy',\n",
       " 'from: Marisazayas1',\n",
       " 'from: AlvearSusana',\n",
       " 'from: wallyboo99',\n",
       " 'from: JulieLKenward',\n",
       " 'from: BioProfBarker',\n",
       " 'from: TakeWeightOffMD',\n",
       " 'from: mdt4129',\n",
       " 'from: maleve',\n",
       " 'from: Hennype85026470',\n",
       " 'from: RolandBakerIII',\n",
       " 'from: Jul101Vie',\n",
       " 'from: Di_ACM_Astro',\n",
       " 'from: CitiBE',\n",
       " 'from: DeniseEngle7',\n",
       " 'from: mabian',\n",
       " 'from: stephaniekays',\n",
       " 'from: luyibov',\n",
       " 'from: TinResistAgain',\n",
       " 'from: maestrasjd',\n",
       " 'from: VictoriaAnnKei',\n",
       " 'from: NIH_NCCIH',\n",
       " 'from: OliviaRosa_',\n",
       " 'from: ArthurZork',\n",
       " 'from: what_speed',\n",
       " 'from: snowflake_not',\n",
       " 'from: tigerbeat',\n",
       " 'from: PoliReliSport',\n",
       " 'from: JonathanLSeagul',\n",
       " 'from: scibib',\n",
       " 'from: KiPoiNeau',\n",
       " 'from: Rng314',\n",
       " 'from: LJLMD',\n",
       " 'from: BobC7000',\n",
       " 'from: PropCazhPM',\n",
       " 'from: JDawsonTweets',\n",
       " 'from: MaryLandrigan',\n",
       " 'from: SMHred',\n",
       " 'from: terry_guta',\n",
       " 'from: MLallai',\n",
       " 'from: RalA19774067',\n",
       " 'from: MutantPrime',\n",
       " 'from: marc_cart',\n",
       " 'from: Donnajcherold',\n",
       " 'from: apuakoronaan',\n",
       " 'from: FINNIN1',\n",
       " 'from: castlemead',\n",
       " 'from: MRedsecker',\n",
       " 'from: steveashleyplus',\n",
       " 'from: NatGlendening',\n",
       " 'from: denver_rose',\n",
       " 'from: mhp1604',\n",
       " 'from: CycloneJonesesq',\n",
       " 'from: doctorozono',\n",
       " 'from: jekbradbury',\n",
       " 'from: bringyourvoice',\n",
       " 'from: DinaZied',\n",
       " 'from: Sheila413375',\n",
       " 'from: zlatev101',\n",
       " 'from: sophiemamanMD',\n",
       " 'from: ARIAGuideline',\n",
       " 'from: jaburrou',\n",
       " 'from: NotGeauxGabby',\n",
       " 'from: TrumpWatchNews',\n",
       " 'from: kclarkcollege',\n",
       " 'from: acosta_cynthia',\n",
       " 'from: vips22',\n",
       " 'from: JoseLoera',\n",
       " 'from: KDOgGetPOd',\n",
       " 'from: pathogenomenick',\n",
       " 'from: Miti_Vigliero',\n",
       " 'from: nabookire',\n",
       " 'from: feministwice',\n",
       " 'from: HawkScreams',\n",
       " 'from: erinlanahan',\n",
       " 'from: joylowell',\n",
       " 'from: Camarlenco',\n",
       " 'from: MaiadeLuna2',\n",
       " 'from: Vi_VIorg',\n",
       " 'from: spaceninja',\n",
       " 'from: scotianselkie',\n",
       " 'from: WonderWhereIAm1',\n",
       " 'from: sandrapcampos',\n",
       " 'from: alcinx',\n",
       " 'from: coueslana',\n",
       " 'from: anniebdwy',\n",
       " 'from: ParryPierce',\n",
       " 'from: EktaShahMD',\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usernames_sample_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Getting filters for N different APIs keys\n",
    "\n",
    "rules_per_api = {}\n",
    "api_number = 0\n",
    "max_filters =20\n",
    "max_rule_string_cap = 400\n",
    "start_i = 0 \n",
    "\n",
    "while start_i < len(usernames_sample_list):\n",
    "    filter_str_multiple_rules = []\n",
    "    for i in range(max_filters):\n",
    "        batch_of_users_filters = 30\n",
    "        end_id = start_i + batch_of_users_filters\n",
    "        if end_id > len(usernames_sample_list):\n",
    "            start_i = end_id\n",
    "            break\n",
    "        filter_str = ' OR '.join(usernames_sample_list[start_i : end_id])\n",
    "        while len(filter_str) > max_rule_string_cap: # Rules up to 512 characters long\n",
    "            end_id = end_id - 1\n",
    "            filter_str = ' OR '.join(usernames_sample_list[start_i : end_id])\n",
    "        start_i = end_id\n",
    "        filter_str_multiple_rules.append(filter_str)\n",
    "    rules_per_api[api_number] = filter_str_multiple_rules\n",
    "    api_number += 1\n",
    "    # Adding Streaming Rule based on Username\n",
    "    # streaming_client.add_rules(tweepy.StreamRule(filter_str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_client = StreamingClient(BEARER_TOKEN_7)\n",
    "previousRules = streaming_client.get_rules().data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(rules_per_api[3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- BEARER_TOKEN_7 => rules_per_api[3][:4]\n",
    "- BEARER_TOKEN_5 => rules_per_api[0][:5]\n",
    "- BEARER_TOKEN_4 => rules_per_api[0][5:20]\n",
    "- BEARER_TOKEN_3 => rules_per_api[1]\n",
    "- BEARER_TOKEN_2 => rules_per_api[3][5:10]\n",
    "- BEARER_TOKEN => rules_per_api[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "ename": "TooManyRequests",
     "evalue": "429 Too Many Requests\nToo Many Requests",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTooManyRequests\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[111], line 7\u001b[0m\n\u001b[1;32m      2\u001b[0m i\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m rule \u001b[39min\u001b[39;00m rules_per_api[\u001b[39m3\u001b[39m][\u001b[39m16\u001b[39m:]:\n\u001b[1;32m      4\u001b[0m     \u001b[39m# print(len(rule))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[39m# i += 1\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     \u001b[39m# print(rule)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     streaming_client\u001b[39m.\u001b[39;49madd_rules(tweepy\u001b[39m.\u001b[39;49mStreamRule(rule))\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tweepy/streaming.py:681\u001b[0m, in \u001b[0;36mStreamingClient.add_rules\u001b[0;34m(self, add, **params)\u001b[0m\n\u001b[1;32m    678\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    679\u001b[0m         json[\u001b[39m\"\u001b[39m\u001b[39madd\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mappend({\u001b[39m\"\u001b[39m\u001b[39mvalue\u001b[39m\u001b[39m\"\u001b[39m: rule\u001b[39m.\u001b[39mvalue})\n\u001b[0;32m--> 681\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[1;32m    682\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mPOST\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m/2/tweets/search/stream/rules\u001b[39;49m\u001b[39m\"\u001b[39;49m, params\u001b[39m=\u001b[39;49mparams,\n\u001b[1;32m    683\u001b[0m     endpoint_parameters\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mdry_run\u001b[39;49m\u001b[39m\"\u001b[39;49m,), json\u001b[39m=\u001b[39;49mjson, data_type\u001b[39m=\u001b[39;49mStreamRule\n\u001b[1;32m    684\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tweepy/client.py:129\u001b[0m, in \u001b[0;36mBaseClient._make_request\u001b[0;34m(self, method, route, params, endpoint_parameters, json, data_type, user_auth)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_make_request\u001b[39m(\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m, method, route, params\u001b[39m=\u001b[39m{}, endpoint_parameters\u001b[39m=\u001b[39m(), json\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    125\u001b[0m     data_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, user_auth\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    126\u001b[0m ):\n\u001b[1;32m    127\u001b[0m     request_params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_params(params, endpoint_parameters)\n\u001b[0;32m--> 129\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest(method, route, params\u001b[39m=\u001b[39;49mrequest_params,\n\u001b[1;32m    130\u001b[0m                             json\u001b[39m=\u001b[39;49mjson, user_auth\u001b[39m=\u001b[39;49muser_auth)\n\u001b[1;32m    132\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_type \u001b[39mis\u001b[39;00m requests\u001b[39m.\u001b[39mResponse:\n\u001b[1;32m    133\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/tweepy/client.py:115\u001b[0m, in \u001b[0;36mBaseClient.request\u001b[0;34m(self, method, route, params, json, user_auth)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest(method, route, params, json, user_auth)\n\u001b[1;32m    114\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 115\u001b[0m         \u001b[39mraise\u001b[39;00m TooManyRequests(response)\n\u001b[1;32m    116\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m500\u001b[39m:\n\u001b[1;32m    117\u001b[0m     \u001b[39mraise\u001b[39;00m TwitterServerError(response)\n",
      "\u001b[0;31mTooManyRequests\u001b[0m: 429 Too Many Requests\nToo Many Requests"
     ]
    }
   ],
   "source": [
    "streaming_client = StreamingClient(BEARER_TOKEN_6)\n",
    "i=1\n",
    "for rule in rules_per_api[3][16:]:\n",
    "    # print(len(rule))\n",
    "    # i += 1\n",
    "    # print(rule)\n",
    "    streaming_client.add_rules(tweepy.StreamRule(rule))\n",
    "    # pass\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming_client = StreamingClient(BEARER_TOKEN)\n",
    "# streaming_client.add_rules(tweepy.StreamRule(filter_str + ' OR from: snowstorm2105'))\n",
    "\n",
    "# Delete previous rules as they exist indefinitely until deleted\n",
    "streaming_client = StreamingClient(BEARER_TOKEN_6)\n",
    "previousRules = streaming_client.get_rules().data\n",
    "if previousRules:\n",
    "    streaming_client.delete_rules(previousRules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rules_per_api[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming_client = StreamingClient(BEARER_TOKEN_6)\n",
    "# streaming_client.get_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# streaming_client = StreamingClient(BEARER_TOKEN_2)\n",
    "# streaming_client.get_rules()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Exception\n"
     ]
    }
   ],
   "source": [
    "tweets_list_for_dataframe = []\n",
    "users_list_for_dataframe = []\n",
    "streaming_client = StreamingClient(BEARER_TOKEN)\n",
    "# streaming_client.add_rules(tweepy.StreamRule(user_filters))\n",
    "# print(streaming_client.get_rules())\n",
    "# Create CSV file\n",
    "\n",
    "if not os.path.exists(f\"data/tweets-stream.csv\"):\n",
    "    with open(\"data/tweets-stream.csv\", \"a+\", encoding='utf-8') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerows([tweet_columns])\n",
    "\n",
    "if not os.path.exists(f\"data/users-stream.csv\"):\n",
    "    with open(\"data/users-stream.csv\", \"a+\", encoding='utf-8') as f:\n",
    "        write = csv.writer(f)\n",
    "        write.writerows([user_columns])\n",
    "\n",
    "# tags = [\"hate speech\"]\n",
    "# streaming_client.sample(expansions='author_id', tweet_fields='created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo', user_fields='created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld')\n",
    "streaming_client.filter(expansions='author_id', tweet_fields='created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo', user_fields='created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Stream' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/stream_search.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/stream_search.ipynb#X24sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m api \u001b[39m=\u001b[39m tweepy\u001b[39m.\u001b[39mAPI(auth)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/stream_search.ipynb#X24sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# initialize stream\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/stream_search.ipynb#X24sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m streamListener \u001b[39m=\u001b[39m Stream()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/stream_search.ipynb#X24sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m stream \u001b[39m=\u001b[39m tweepy\u001b[39m.\u001b[39mStream(auth\u001b[39m=\u001b[39mapi\u001b[39m.\u001b[39mauth, listener\u001b[39m=\u001b[39mstreamListener,tweet_mode\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mextended\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/stream_search.ipynb#X24sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mout.csv\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mw\u001b[39m\u001b[39m\"\u001b[39m, encoding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Stream' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # complete authorization and initialize API endpoint\n",
    "    # auth = tweepy.OAuth2BearerHandler(BEARER_TOKEN)\n",
    "    auth = tweepy.Client(BEARER_TOKEN)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    # initialize stream\n",
    "    streamListener = Stream()\n",
    "    stream = tweepy.Stream(auth=api.auth, listener=streamListener,tweet_mode='extended')\n",
    "    with open(\"out.csv\", \"w\", encoding='utf-8') as f:\n",
    "        f.write(\"date,user,is_retweet,is_quote,text,quoted_text\\n\")\n",
    "    tags = [\"hate speech\"]\n",
    "    stream.filter(track=tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/tweets-stream.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/tweets-stream.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/tweets-stream.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/tweets-stream.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possibly_sensitive</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>lang</th>\n",
       "      <th>reply_settings</th>\n",
       "      <th>author_id</th>\n",
       "      <th>edit_history_tweet_ids</th>\n",
       "      <th>hashtags_list</th>\n",
       "      <th>urls_list</th>\n",
       "      <th>public_metrics_retweet_count</th>\n",
       "      <th>public_metrics_reply_count</th>\n",
       "      <th>public_metrics_like_count</th>\n",
       "      <th>public_metrics_quote_count</th>\n",
       "      <th>pagination_token</th>\n",
       "      <th>current_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>RT @weedside0: hija de papi? si, por????</td>\n",
       "      <td>Twitter for iPad</td>\n",
       "      <td>1590904766871502848</td>\n",
       "      <td>2022-11-11T03:10:28.000Z</td>\n",
       "      <td>es</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1283839616810995712</td>\n",
       "      <td>['1590904766871502848']</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>2117</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-10 19:10:33.057126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>RT @YukiSacura: \\n\\n\\n\\...</td>\n",
       "      <td>Twitter Web App</td>\n",
       "      <td>1590904766888284161</td>\n",
       "      <td>2022-11-11T03:10:28.000Z</td>\n",
       "      <td>ja</td>\n",
       "      <td>everyone</td>\n",
       "      <td>1521270807460478976</td>\n",
       "      <td>['1590904766888284161']</td>\n",
       "      <td>['AMAs']</td>\n",
       "      <td>[]</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-10 19:10:33.058297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>RT @AleB1808: Ni as la gente quiere volar de ...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1590904766867161090</td>\n",
       "      <td>2022-11-11T03:10:28.000Z</td>\n",
       "      <td>es</td>\n",
       "      <td>everyone</td>\n",
       "      <td>974578403692109824</td>\n",
       "      <td>['1590904766867161090']</td>\n",
       "      <td>[]</td>\n",
       "      <td>['https://twitter.com/AleB1808/status/15908799...</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-10 19:10:33.060218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>It's about damn time! Sanctioning lawyers shou...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1590904766866984960</td>\n",
       "      <td>2022-11-11T03:10:28.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>975364111</td>\n",
       "      <td>['1590904766866984960']</td>\n",
       "      <td>['SmartNews']</td>\n",
       "      <td>['https://l.smartnews.com/oqzhk/MAVqeR']</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-10 19:10:33.060988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>MBB: 2nd Half | 18:57\\nThe Saints start off th...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>1590904766875553793</td>\n",
       "      <td>2022-11-11T03:10:28.000Z</td>\n",
       "      <td>en</td>\n",
       "      <td>everyone</td>\n",
       "      <td>56516160</td>\n",
       "      <td>['1590904766875553793']</td>\n",
       "      <td>['SCCCSaints', 'GoodToBeGreen']</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-11-10 19:10:33.061604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   possibly_sensitive                                               text  \\\n",
       "0               False           RT @weedside0: hija de papi? si, por????   \n",
       "1               False  RT @YukiSacura: \\n\\n\\n\\...   \n",
       "2               False  RT @AleB1808: Ni as la gente quiere volar de ...   \n",
       "3               False  It's about damn time! Sanctioning lawyers shou...   \n",
       "4               False  MBB: 2nd Half | 18:57\\nThe Saints start off th...   \n",
       "\n",
       "                source                   id                created_at lang  \\\n",
       "0     Twitter for iPad  1590904766871502848  2022-11-11T03:10:28.000Z   es   \n",
       "1      Twitter Web App  1590904766888284161  2022-11-11T03:10:28.000Z   ja   \n",
       "2  Twitter for Android  1590904766867161090  2022-11-11T03:10:28.000Z   es   \n",
       "3  Twitter for Android  1590904766866984960  2022-11-11T03:10:28.000Z   en   \n",
       "4  Twitter for Android  1590904766875553793  2022-11-11T03:10:28.000Z   en   \n",
       "\n",
       "  reply_settings            author_id   edit_history_tweet_ids  \\\n",
       "0       everyone  1283839616810995712  ['1590904766871502848']   \n",
       "1       everyone  1521270807460478976  ['1590904766888284161']   \n",
       "2       everyone   974578403692109824  ['1590904766867161090']   \n",
       "3       everyone            975364111  ['1590904766866984960']   \n",
       "4       everyone             56516160  ['1590904766875553793']   \n",
       "\n",
       "                     hashtags_list  \\\n",
       "0                               []   \n",
       "1                         ['AMAs']   \n",
       "2                               []   \n",
       "3                    ['SmartNews']   \n",
       "4  ['SCCCSaints', 'GoodToBeGreen']   \n",
       "\n",
       "                                           urls_list  \\\n",
       "0                                                 []   \n",
       "1                                                 []   \n",
       "2  ['https://twitter.com/AleB1808/status/15908799...   \n",
       "3           ['https://l.smartnews.com/oqzhk/MAVqeR']   \n",
       "4                                                 []   \n",
       "\n",
       "   public_metrics_retweet_count  public_metrics_reply_count  \\\n",
       "0                          2117                           0   \n",
       "1                            88                           0   \n",
       "2                            68                           0   \n",
       "3                             0                           0   \n",
       "4                             0                           0   \n",
       "\n",
       "   public_metrics_like_count  public_metrics_quote_count  pagination_token  \\\n",
       "0                          0                           0               NaN   \n",
       "1                          0                           0               NaN   \n",
       "2                          0                           0               NaN   \n",
       "3                          0                           0               NaN   \n",
       "4                          0                           0               NaN   \n",
       "\n",
       "                 current_time  \n",
       "0  2022-11-10 19:10:33.057126  \n",
       "1  2022-11-10 19:10:33.058297  \n",
       "2  2022-11-10 19:10:33.060218  \n",
       "3  2022-11-10 19:10:33.060988  \n",
       "4  2022-11-10 19:10:33.061604  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/users-0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'29mustafaeser',\n",
       " 'ASainzBScP',\n",
       " 'AathiNesh',\n",
       " 'AgProgressUSA',\n",
       " 'CNNIndonesia',\n",
       " 'CatalunyaPlural',\n",
       " 'ELLEfrance',\n",
       " 'HungryHoss',\n",
       " 'JulieAisyah2',\n",
       " 'LuckyVish4',\n",
       " 'Magnolia48693',\n",
       " 'Nifemi_Olu',\n",
       " 'Reyconfidant',\n",
       " 'Sir_Onkzt',\n",
       " 'UyumluTris',\n",
       " 'WBRCnews',\n",
       " 'WhitehPaul',\n",
       " 'Ymbjmrf',\n",
       " '_anemones',\n",
       " '_creamys',\n",
       " 'alooislife',\n",
       " 'bduadieu13',\n",
       " 'btssjkjinchook',\n",
       " 'deformingIii',\n",
       " 'detikHealth',\n",
       " 'diaricece',\n",
       " 'eevriviades',\n",
       " 'gnutiez',\n",
       " 'greeenfroggg',\n",
       " 'kolikVylecenych',\n",
       " 'sayyidfath',\n",
       " 'seraph_wren',\n",
       " 'suimu2013',\n",
       " 'taehuj',\n",
       " 'tjwhizkid',\n",
       " 'veerlemichielss',\n",
       " 'yamunaoverseas',\n",
       " 'yoonie579'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(df['username'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed29fcc266c631214eb0a32dcb461d51a7279cf73c87ecfbb65b364d13f4dbad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
