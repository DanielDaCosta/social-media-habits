{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='AppServerStatus.log', encoding='utf-8', level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Crentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "CONSUMER_KEY = config['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = config['CONSUMER_SECRET']\n",
    "BEARER_TOKEN = config['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Archive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {BEARER_TOKEN}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def main(url, params):\n",
    "    json_response = connect_to_endpoint(url, params)\n",
    "    # print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {\n",
    "    'query': '(from:twitterdev) has:links has:hashtags lang:en',\n",
    "    'user.fields': 'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld',\n",
    "    'tweet.fields': 'created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo',\n",
    "    'expansions': 'author_id',\n",
    "    'start_time': '2021-01-01T02:07:14Z',\n",
    "    'end_time': '2021-12-01T02:07:14Z'\n",
    "}\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "output_tweets = main(search_url, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "469946466"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "userid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tweet & Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {\n",
    "    'query': '(from:twitterdev) has:links has:hashtags lang:en',\n",
    "    'user.fields': 'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld',\n",
    "    'tweet.fields': 'created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo',\n",
    "    'expansions': 'author_id',\n",
    "    'start_time': '2021-01-01T02:07:14Z',\n",
    "    'end_time': '2021-12-01T02:07:14Z'\n",
    "}\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "output_tweets = main(search_url, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_items(list_of_dict: list, key_name: str) -> list:\n",
    "    if not list_of_dict: # If list_of_dict is None\n",
    "        return []\n",
    "    return [entity[key_name] for entity in list_of_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities(tweet_entities: dict, object_dict: dict, prefix: str = '') -> dict:\n",
    "    entities_dict = defaultdict(list)\n",
    "\n",
    "    # Retrieve Entities Objects\n",
    "    for object_name, key_name in object_dict.items():\n",
    "        column_name = f\"{prefix}{object_name}_list\"\n",
    "        # print(object_name)\n",
    "        entities_dict[column_name] = get_list_of_items(tweet_entities.get(object_name), key_name)\n",
    "    return entities_dict\n",
    "    # entities_dict['hashtags_list'] = get_list_of_items(tweet_entities['hashtags'], 'tag')\n",
    "    # entities_dict['urls_list'] = get_list_of_items(tweet_entities['urls'], 'expanded_url')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dict_object(object_dict: dict, column_prefix: str,key_names_list: list = []) -> dict:\n",
    "    \"\"\"Return key,value pairs from dict. Returns selected keys in key_names_list or all if key_names_list is []\n",
    "\n",
    "    Args:\n",
    "        object_dict (dict)\n",
    "        key_names_list (list)\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    result_dict = defaultdict(list)\n",
    "    for key_name, value_name in object_dict.items():\n",
    "        column_name = f\"{column_prefix}_{key_name}\"\n",
    "        if not key_names_list:\n",
    "            result_dict[column_name] = value_name\n",
    "        elif key_name in key_names_list:\n",
    "            result_dict[column_name] = value_name\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tweets_columns = [\n",
    "    'id', 'author_id', 'possibly_sensitive', 'edit_history_tweet_ids', 'lang',\n",
    "    'source', 'reply_settings', 'text', 'created_at'\n",
    "]\n",
    "\n",
    "json_users_columns = [\n",
    "    'id', 'name', 'username', 'location', 'url', 'created_at', 'username',\n",
    "    'profile_image_url', 'profile_image_url', 'verified', 'description',\n",
    "    'protected'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list_for_dataframe = []\n",
    "users_list_for_dataframe = []\n",
    "next_token = {'next_token': output['meta']['next_token']}\n",
    "logging.info(f'Twitter URL: {search_url}')\n",
    "logging.info(f'Params: {query_params}')\n",
    "\n",
    "for tweet in output_tweets['data']:\n",
    "    # Get new columns\n",
    "    entities_dict = parse_entities(tweet['entities'], {'hashtags': 'tag', 'urls': 'expanded_url'})\n",
    "    public_metrics_dict = expand_dict_object(tweet['public_metrics'], 'public_metrics')\n",
    "\n",
    "    # Filter out unwanted columns\n",
    "    tweet = {key: tweet[key] for key in tweet.keys() if key in json_tweets_columns}\n",
    "\n",
    "    # Combine dicts\n",
    "    tweet = {**tweet, **entities_dict, **public_metrics_dict, **next_token}\n",
    "    tweets_list_for_dataframe.append(tweet)\n",
    "\n",
    "for user in output_tweets['includes']['users']:\n",
    "    # Get new columns\n",
    "    url_dict = parse_entities(user['entities']['url'], {'urls': 'expanded_url'}, prefix='url_')\n",
    "\n",
    "    description_dict = parse_entities(\n",
    "        user['entities']['description'],\n",
    "        {'hashtags': 'tag', 'urls': 'expanded_url', 'mentions': 'tag', 'cashtags': 'tag'}, prefix='description_')\n",
    "    user_public_metrics_dict = expand_dict_object(user['public_metrics'], 'public_metrics')\n",
    "    # Filter out unwanted columns\n",
    "    user = {key: user[key] for key in user.keys() if key in json_users_columns}\n",
    "\n",
    "    # Combine dicts\n",
    "    user = {**user, **url_dict, **description_dict, **user_public_metrics_dict}\n",
    "    users_list_for_dataframe.append(user)\n",
    "\n",
    "logging.info(f\"Next token: {output_tweets['meta']['next_token']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve data from users AVAX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/7czjs3z54yd54jz8j2ktmygc0000gn/T/ipykernel_28682/2012370649.py:1: DtypeWarning: Columns (6,7,8,9,10,11,12,13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('0.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_id_list = set(df['userid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Start and End Time with 6 month interval\n",
    "\n",
    "END_TIME = '2022-10-01T00:00:00Z'\n",
    "END_TIME_DATETIME = datetime.strptime(START_TIME, '%Y-%m-%dT%H:%M:%SZ')\n",
    "START_TIME_DATETIME = END_TIME_DATETIME - relativedelta(months=6) # 6 Months Window\n",
    "START_TIME = START_TIME_DATETIME.strftime('%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "current_time = datetime.now()\n",
    "\n",
    "date = f'{current_time.year}-{current_time.month:02d}-{current_time.day:02d}'\n",
    "time = f'{current_time.hour:02d}-{current_time.minute:02d}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "(429, '{\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb Cell 26\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mfor\u001b[39;00m userid \u001b[39min\u001b[39;00m \u001b[39mlist\u001b[39m(users_id_list)[\u001b[39m30\u001b[39m:]: \u001b[39m# There are 200 users id\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     \u001b[39m# Query Data from API\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     query_params[\u001b[39m'\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m(from:\u001b[39m\u001b[39m{\u001b[39;00muserid\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     output_tweets \u001b[39m=\u001b[39m main(search_url, query_params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     next_token \u001b[39m=\u001b[39m {}\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     next_token[\u001b[39m'\u001b[39m\u001b[39mnext_token\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m output_tweets[\u001b[39m'\u001b[39m\u001b[39mmeta\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mnext_token\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb Cell 26\u001b[0m in \u001b[0;36mmain\u001b[0;34m(url, params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmain\u001b[39m(url, params):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     json_response \u001b[39m=\u001b[39m connect_to_endpoint(url, params)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39m# print(json.dumps(json_response, indent=4, sort_keys=True))\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m json_response\n",
      "\u001b[1;32m/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb Cell 26\u001b[0m in \u001b[0;36mconnect_to_endpoint\u001b[0;34m(url, params)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m response \u001b[39m=\u001b[39m requests\u001b[39m.\u001b[39mget(url, auth\u001b[39m=\u001b[39mbearer_oauth, params\u001b[39m=\u001b[39mparams)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mif\u001b[39;00m response\u001b[39m.\u001b[39mstatus_code \u001b[39m!=\u001b[39m \u001b[39m200\u001b[39m:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mException\u001b[39;00m(response\u001b[39m.\u001b[39mstatus_code, response\u001b[39m.\u001b[39mtext)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/danieldacosta/Documents/USC/SM-Habits/social-media-habits/archive_search.ipynb#X62sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mjson()\n",
      "\u001b[0;31mException\u001b[0m: (429, '{\"title\":\"Too Many Requests\",\"detail\":\"Too Many Requests\",\"type\":\"about:blank\",\"status\":429}')"
     ]
    }
   ],
   "source": [
    "batch_of_users = 0 # 0.csv\n",
    "tweets_list_for_dataframe = []\n",
    "users_list_for_dataframe = []\n",
    "\n",
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {\n",
    "    # 'query': '(from:twitterdev) has:links has:hashtags lang:en',\n",
    "    'user.fields': 'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld',\n",
    "    'tweet.fields': 'created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo',\n",
    "    'expansions': 'author_id',\n",
    "    'start_time': START_TIME,\n",
    "    'end_time': END_TIME,\n",
    "    'max_results': 500\n",
    "}\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "\n",
    "for userid in list(users_id_list)[30:]: # There are 200 users id\n",
    "\n",
    "    # Query Data from API\n",
    "    query_params['query'] = f'(from:{userid})'\n",
    "    output_tweets = main(search_url, query_params)\n",
    "    next_token = {}\n",
    "    next_token['next_token'] = output_tweets['meta'].get('next_token')\n",
    "    if next_token['next_token']:\n",
    "        query_params['next_token'] = next_token['next_token']\n",
    "    logging.info(f'Twitter URL: {search_url}')\n",
    "    logging.info(f'Params: {query_params}')\n",
    "\n",
    "    # If no data found:\n",
    "    if not output_tweets.get('data'):\n",
    "        logging.warning(f'No data found for userId {userid}')\n",
    "        continue\n",
    "\n",
    "    for tweet in output_tweets['data']:\n",
    "        # Get new columns\n",
    "        if not tweet.get('entities'):\n",
    "            entities_dict = parse_entities({}, {'hashtags': 'tag', 'urls': 'expanded_url'})\n",
    "        else:\n",
    "            entities_dict = parse_entities(tweet['entities'], {'hashtags': 'tag', 'urls': 'expanded_url'})\n",
    "        \n",
    "        if not tweet.get('public_metrics'):\n",
    "            public_metrics_dict = expand_dict_object({}, 'public_metrics')\n",
    "        else:\n",
    "            public_metrics_dict = expand_dict_object(tweet['public_metrics'], 'public_metrics')\n",
    "\n",
    "        # Filter out unwanted columns\n",
    "        tweet = {key: tweet[key] for key in tweet.keys() if key in json_tweets_columns}\n",
    "\n",
    "        # Combine dicts\n",
    "        tweet = {**tweet, **entities_dict, **public_metrics_dict, **next_token}\n",
    "        tweets_list_for_dataframe.append(tweet)\n",
    "\n",
    "    for user in output_tweets['includes']['users']:\n",
    "\n",
    "        # Get new columns\n",
    "        if (not user.get('entities')) or (not user.get('entities').get('url')):\n",
    "            url_dict = parse_entities({}, {'urls': 'expanded_url'}, prefix='url_')\n",
    "        else:\n",
    "            url_dict = parse_entities(user['entities']['url'], {'urls': 'expanded_url'}, prefix='url_')\n",
    "\n",
    "        if (not user.get('entities')) or (not user.get('entities').get('description')):\n",
    "            description_dict = parse_entities(\n",
    "                {},\n",
    "                {'hashtags': 'tag', 'urls': 'expanded_url', 'mentions': 'username', 'cashtags': 'tag'}, prefix='description_')\n",
    "        else:\n",
    "            description_dict = parse_entities(\n",
    "                user['entities']['description'],\n",
    "                {'hashtags': 'tag', 'urls': 'expanded_url', 'mentions': 'username', 'cashtags': 'tag'}, prefix='description_')\n",
    "\n",
    "        user_public_metrics_dict = expand_dict_object(user['public_metrics'], 'public_metrics')\n",
    "        # Filter out unwanted columns\n",
    "        user = {key: user[key] for key in user.keys() if key in json_users_columns}\n",
    "\n",
    "        # Combine dicts\n",
    "        user = {**user, **url_dict, **description_dict, **user_public_metrics_dict}\n",
    "        users_list_for_dataframe.append(user)\n",
    "\n",
    "    # logging.info(f\"Next token: {output_tweets['meta']['next_token']}\")\n",
    "    # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =  pd.DataFrame.from_records(tweets_list_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.DataFrame.from_records(users_list_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv(f'data/tweets-{batch_of_users}-{date}-{time}.csv', index=False)\n",
    "users.to_csv(f'data/users-{batch_of_users}-{date}-{time}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets[tweets['next_token'] == 'b26v89c19zqg8o3fpytl0ibacdbf7wx9x2ebhdl7rmqgt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1047544362',\n",
       " '118232657',\n",
       " '1301434620777390080',\n",
       " '1362335834',\n",
       " '184352307',\n",
       " '214811214',\n",
       " '22882864',\n",
       " '250104916',\n",
       " '2829202522',\n",
       " '318489159',\n",
       " '607053909',\n",
       " '718944819',\n",
       " '919185985132466176'}"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tweets['author_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed29fcc266c631214eb0a32dcb461d51a7279cf73c87ecfbb65b364d13f4dbad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
