{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='AppServerStatus.log', encoding='utf-8', level=logging.DEBUG, force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Crentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "CONSUMER_KEY = config['CONSUMER_KEY']\n",
    "CONSUMER_SECRET = config['CONSUMER_SECRET']\n",
    "BEARER_TOKEN = config['BEARER_TOKEN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full Archive Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sv/7czjs3z54yd54jz8j2ktmygc0000gn/T/ipykernel_33811/2012370649.py:1: DtypeWarning: Columns (6,7,8,9,10,11,12,13,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('0.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {BEARER_TOKEN}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2RecentSearchPython\"\n",
    "    return r\n",
    "\n",
    "def connect_to_endpoint(url, params):\n",
    "    response = requests.get(url, auth=bearer_oauth, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(response.status_code, response.text)\n",
    "    return response.json()\n",
    "\n",
    "def main(url, params):\n",
    "    json_response = connect_to_endpoint(url, params)\n",
    "    # print(json.dumps(json_response, indent=4, sort_keys=True))\n",
    "    return json_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Tweet & Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional params: start_time,end_time,since_id,until_id,max_results,next_token,\n",
    "# expansions,tweet.fields,media.fields,poll.fields,place.fields,user.fields\n",
    "query_params = {\n",
    "    'query': '(from:twitterdev) has:links has:hashtags lang:en',\n",
    "    'user.fields': 'created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld',\n",
    "    'tweet.fields': 'created_at,public_metrics,entities,lang,possibly_sensitive,reply_settings,source,in_reply_to_user_id,geo',\n",
    "    'expansions': 'author_id',\n",
    "    'start_time': '2021-01-01T02:07:14Z',\n",
    "    'end_time': '2021-12-01T02:07:14Z'\n",
    "}\n",
    "search_url = \"https://api.twitter.com/2/tweets/search/all\"\n",
    "\n",
    "output_tweets = main(search_url, query_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_items(list_of_dict: list, key_name: str) -> list:\n",
    "    if not list_of_dict: # If list_of_dict is None\n",
    "        return []\n",
    "    return [entity[key_name] for entity in list_of_dict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_entities(tweet_entities: dict, object_dict: dict, prefix: str = '') -> dict:\n",
    "    entities_dict = defaultdict(list)\n",
    "\n",
    "    # Retrieve Entities Objects\n",
    "    for object_name, key_name in object_dict.items():\n",
    "        column_name = f\"{prefix}{object_name}_list\"\n",
    "        entities_dict[column_name] = get_list_of_items(tweet_entities.get(object_name), key_name)\n",
    "    return entities_dict\n",
    "    # entities_dict['hashtags_list'] = get_list_of_items(tweet_entities['hashtags'], 'tag')\n",
    "    # entities_dict['urls_list'] = get_list_of_items(tweet_entities['urls'], 'expanded_url')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_dict_object(object_dict: dict, column_prefix: str,key_names_list: list = []) -> dict:\n",
    "    \"\"\"Return key,value pairs from dict. Returns selected keys in key_names_list or all if key_names_list is []\n",
    "\n",
    "    Args:\n",
    "        object_dict (dict)\n",
    "        key_names_list (list)\n",
    "    Returns:\n",
    "        dict\n",
    "    \"\"\"\n",
    "    result_dict = defaultdict(list)\n",
    "    for key_name, value_name in object_dict.items():\n",
    "        column_name = f\"{column_prefix}_{key_name}\"\n",
    "        if not key_names_list:\n",
    "            result_dict[column_name] = value_name\n",
    "        elif key_name in key_names_list:\n",
    "            result_dict[column_name] = value_name\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_tweets_columns = [\n",
    "    'id', 'author_id', 'possibly_sensitive', 'edit_history_tweet_ids', 'lang',\n",
    "    'source', 'reply_settings', 'text', 'created_at'\n",
    "]\n",
    "\n",
    "json_users_columns = [\n",
    "    'id', 'name', 'username', 'location', 'url', 'created_at', 'username',\n",
    "    'profile_image_url', 'profile_image_url', 'verified', 'description',\n",
    "    'protected'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_list_for_dataframe = []\n",
    "users_list_for_dataframe = []\n",
    "next_token = {'next_token': output['meta']['next_token']}\n",
    "logging.info(f'Twitter URL: {search_url}')\n",
    "logging.info(f'Params: {query_params}')\n",
    "\n",
    "for tweet in output_tweets['data']:\n",
    "    # Get new columns\n",
    "    entities_dict = parse_entities(tweet['entities'], {'hashtags': 'tag', 'urls': 'expanded_url'})\n",
    "    public_metrics_dict = expand_dict_object(tweet['public_metrics'], 'public_metrics')\n",
    "\n",
    "    # Filter out unwanted columns\n",
    "    tweet = {key: tweet[key] for key in tweet.keys() if key in json_tweets_columns}\n",
    "\n",
    "    # Combine dicts\n",
    "    tweet = {**tweet, **entities_dict, **public_metrics_dict, **next_token}\n",
    "    tweets_list_for_dataframe.append(tweet)\n",
    "\n",
    "for user in output_tweets['includes']['users']:\n",
    "    # Get new columns\n",
    "    url_dict = parse_entities(user['entities']['url'], {'urls': 'expanded_url'}, prefix='url_')\n",
    "\n",
    "    description_dict = parse_entities(\n",
    "        user['entities']['description'],\n",
    "        {'hashtags': 'tag', 'urls': 'expanded_url', 'mentions': 'tag', 'cashtags': 'tag'}, prefix='description_')\n",
    "    user_public_metrics_dict = expand_dict_object(user['public_metrics'], 'public_metrics')\n",
    "    # Filter out unwanted columns\n",
    "    user = {key: user[key] for key in user.keys() if key in json_users_columns}\n",
    "\n",
    "    # Combine dicts\n",
    "    user = {**user, **url_dict, **description_dict, **user_public_metrics_dict}\n",
    "    users_list_for_dataframe.append(user)\n",
    "\n",
    "logging.info(f\"Next token: {output_tweets['meta']['next_token']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.DataFrame.from_records(users_list_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets =  pd.DataFrame.from_records(tweets_list_for_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.to_csv('data/users.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.to_csv('data/tweets.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ed29fcc266c631214eb0a32dcb461d51a7279cf73c87ecfbb65b364d13f4dbad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
